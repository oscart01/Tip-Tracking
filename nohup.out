Train files loaded
Validation files loaded
HopeNet is loaded
Begin training the network...
[1001,    50] loss: 4620.84814
[1001,   100] loss: 3277.96216
[1001,   150] loss: 2920.03247
/root/miniconda3/envs/hope/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/root/miniconda3/envs/hope/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 3])) that is different to the input size (torch.Size([3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
val error: 2062.48462
[1002,    50] loss: 2042.82483
[1002,   100] loss: 2078.95825
[1002,   150] loss: 1549.13354
val error: 840.08038
[1003,    50] loss: 814.35626
[1003,   100] loss: 1552.65515
[1003,   150] loss: 1899.07373
val error: 888.28333
[1004,    50] loss: 821.17603
[1004,   100] loss: 864.08276
[1004,   150] loss: 748.47949
val error: 834.38507
[1005,    50] loss: 600.51239
[1005,   100] loss: 478.53082
[1005,   150] loss: 488.04840
val error: 644.54376
[1006,    50] loss: 287.77832
[1006,   100] loss: 404.31100
[1006,   150] loss: 457.13675
val error: 500.61349
[1007,    50] loss: 322.23795
[1007,   100] loss: 219.39716
[1007,   150] loss: 324.63525
val error: 602.76440
[1008,    50] loss: 230.66765
[1008,   100] loss: 202.09537
[1008,   150] loss: 220.22276
val error: 711.09161
[1009,    50] loss: 243.80025
[1009,   100] loss: 256.51385
[1009,   150] loss: 321.75620
val error: 263.61047
[1010,    50] loss: 321.42520
[1010,   100] loss: 220.35487
[1010,   150] loss: 188.40639
val error: 279.64160
[1011,    50] loss: 141.37854
[1011,   100] loss: 232.01843
[1011,   150] loss: 161.59872
val error: 569.16901
[1012,    50] loss: 239.08344
[1012,   100] loss: 132.16306
[1012,   150] loss: 122.24660
val error: 401.19559
[1013,    50] loss: 127.34756
[1013,   100] loss: 123.65327
[1013,   150] loss: 160.92540
val error: 287.69385
[1014,    50] loss: 116.50703
[1014,   100] loss: 111.22782
[1014,   150] loss: 143.31769
val error: 339.40115
[1015,    50] loss: 165.14684
[1015,   100] loss: 261.88544
[1015,   150] loss: 102.57722
val error: 333.73798
[1016,    50] loss: 380.29630
[1016,   100] loss: 239.93645
[1016,   150] loss: 127.27579
val error: 390.88052
[1017,    50] loss: 119.86954
[1017,   100] loss: 117.29012
[1017,   150] loss: 184.15216
val error: 324.15012
[1018,    50] loss: 142.88982
[1018,   100] loss: 129.15038
[1018,   150] loss: 107.89689
val error: 267.53891
[1019,    50] loss: 118.15515
[1019,   100] loss: 103.73833
[1019,   150] loss: 190.17628
val error: 327.74402
[1020,    50] loss: 124.95058
[1020,   100] loss: 136.05920
[1020,   150] loss: 150.35349
val error: 269.12302
[1021,    50] loss: 177.93541
[1021,   100] loss: 121.70718
[1021,   150] loss: 78.98022
val error: 288.87396
[1022,    50] loss: 122.77792
[1022,   100] loss: 108.34258
[1022,   150] loss: 118.72279
val error: 242.42719
[1023,    50] loss: 115.90437
[1023,   100] loss: 189.28513
[1023,   150] loss: 203.59802
val error: 385.82495
[1024,    50] loss: 140.93724
[1024,   100] loss: 98.14758
[1024,   150] loss: 90.85658
val error: 244.20920
[1025,    50] loss: 159.35478
[1025,   100] loss: 105.64113
[1025,   150] loss: 181.99710
val error: 279.43344
[1026,    50] loss: 99.25788
[1026,   100] loss: 80.89252
[1026,   150] loss: 102.92854
val error: 411.39941
[1027,    50] loss: 151.76126
[1027,   100] loss: 99.37427
[1027,   150] loss: 71.18620
val error: 413.18173
[1028,    50] loss: 94.59705
[1028,   100] loss: 71.71445
[1028,   150] loss: 88.85607
val error: 449.67004
[1029,    50] loss: 111.40495
[1029,   100] loss: 118.41098
[1029,   150] loss: 82.97148
val error: 216.69939
[1030,    50] loss: 130.67842
[1030,   100] loss: 67.45394
[1030,   150] loss: 104.96729
val error: 256.32413
[1031,    50] loss: 189.70216
[1031,   100] loss: 126.82028
[1031,   150] loss: 126.04116
val error: 231.48834
[1032,    50] loss: 173.49062
[1032,   100] loss: 192.46973
[1032,   150] loss: 138.73248
val error: 243.50456
[1033,    50] loss: 109.61609
[1033,   100] loss: 79.78146
[1033,   150] loss: 90.95702
val error: 241.52589
[1034,    50] loss: 123.42953
[1034,   100] loss: 96.03334
[1034,   150] loss: 129.58003
val error: 301.04849
[1035,    50] loss: 109.55413
[1035,   100] loss: 66.23644
[1035,   150] loss: 64.15295
val error: 377.90411
[1036,    50] loss: 101.49439
[1036,   100] loss: 74.49645
[1036,   150] loss: 77.98151
val error: 284.42459
[1037,    50] loss: 101.37553
[1037,   100] loss: 144.12433
[1037,   150] loss: 81.23554
val error: 268.65094
[1038,    50] loss: 133.31302
[1038,   100] loss: 98.07593
[1038,   150] loss: 146.52835
val error: 397.63605
[1039,    50] loss: 120.51842
[1039,   100] loss: 79.39463
[1039,   150] loss: 112.67156
val error: 470.96310
[1040,    50] loss: 131.90765
[1040,   100] loss: 377.84396
[1040,   150] loss: 326.37338
val error: 337.92523
[1041,    50] loss: 127.06543
[1041,   100] loss: 109.10119
[1041,   150] loss: 161.96214
val error: 385.17242
[1042,    50] loss: 119.41635
[1042,   100] loss: 54.83978
[1042,   150] loss: 74.84944
val error: 262.55649
[1043,    50] loss: 52.82426
[1043,   100] loss: 83.19592
[1043,   150] loss: 36.87944
val error: 244.09122
[1044,    50] loss: 48.76160
[1044,   100] loss: 39.59608
[1044,   150] loss: 37.29797
val error: 208.36137
[1045,    50] loss: 27.08298
[1045,   100] loss: 45.50378
[1045,   150] loss: 49.77386
val error: 270.22784
[1046,    50] loss: 109.05181
[1046,   100] loss: 62.25010
[1046,   150] loss: 57.86331
val error: 288.70599
[1047,    50] loss: 43.95090
[1047,   100] loss: 67.09528
[1047,   150] loss: 44.91046
val error: 206.76447
[1048,    50] loss: 37.63195
[1048,   100] loss: 43.00405
[1048,   150] loss: 41.22294
val error: 314.27390
[1049,    50] loss: 102.20574
[1049,   100] loss: 43.23481
[1049,   150] loss: 47.80687
val error: 222.06084
[1050,    50] loss: 53.92122
[1050,   100] loss: 89.69926
[1050,   150] loss: 52.09735
val error: 192.92355
[1051,    50] loss: 62.97038
[1051,   100] loss: 81.91608
[1051,   150] loss: 57.17258
val error: 239.46512
[1052,    50] loss: 55.90691
[1052,   100] loss: 106.85712
[1052,   150] loss: 130.76186
val error: 297.98425
[1053,    50] loss: 106.12434
[1053,   100] loss: 99.36729
[1053,   150] loss: 130.21297
val error: 363.09641
[1054,    50] loss: 67.22212
[1054,   100] loss: 76.25741
[1054,   150] loss: 87.08606
val error: 245.78314
[1055,    50] loss: 130.51559
[1055,   100] loss: 88.36742
[1055,   150] loss: 66.68894
val error: 240.07268
[1056,    50] loss: 50.41017
[1056,   100] loss: 38.27792
[1056,   150] loss: 81.85969
val error: 208.41844
[1057,    50] loss: 48.61497
[1057,   100] loss: 41.97221
[1057,   150] loss: 41.99582
val error: 227.47501
[1058,    50] loss: 39.54209
[1058,   100] loss: 37.35029
[1058,   150] loss: 32.47781
val error: 295.23010
[1059,    50] loss: 45.95003
[1059,   100] loss: 44.14013
[1059,   150] loss: 33.07898
val error: 298.61411
[1060,    50] loss: 50.36484
[1060,   100] loss: 55.90230
[1060,   150] loss: 58.72385
val error: 206.86104
[1061,    50] loss: 63.62286
[1061,   100] loss: 61.14846
[1061,   150] loss: 61.48021
val error: 251.93008
[1062,    50] loss: 37.38709
[1062,   100] loss: 38.60632
[1062,   150] loss: 34.99798
val error: 239.64610
[1063,    50] loss: 40.91024
[1063,   100] loss: 37.47990
[1063,   150] loss: 36.56511
val error: 258.18747
[1064,    50] loss: 42.57843
[1064,   100] loss: 26.22813
[1064,   150] loss: 26.96343
val error: 229.16226
[1065,    50] loss: 43.89762
[1065,   100] loss: 27.85737
[1065,   150] loss: 29.30532
val error: 217.34193
[1066,    50] loss: 24.00236
[1066,   100] loss: 24.53070
[1066,   150] loss: 44.36513
val error: 273.26126
[1067,    50] loss: 71.45190
[1067,   100] loss: 51.56943
[1067,   150] loss: 41.91807
val error: 234.30502
[1068,    50] loss: 39.96756
[1068,   100] loss: 43.22934
[1068,   150] loss: 54.50521
val error: 232.57516
[1069,    50] loss: 51.73981
[1069,   100] loss: 42.78016
[1069,   150] loss: 19.55209
val error: 257.71790
[1070,    50] loss: 50.21919
[1070,   100] loss: 35.05788
[1070,   150] loss: 32.38967
val error: 251.94182
[1071,    50] loss: 36.14348
[1071,   100] loss: 37.74838
[1071,   150] loss: 32.17159
val error: 306.04050
[1072,    50] loss: 46.05337
[1072,   100] loss: 26.65691
[1072,   150] loss: 34.32307
val error: 248.58144
[1073,    50] loss: 26.39975
[1073,   100] loss: 30.72385
[1073,   150] loss: 25.20429
val error: 236.45631
[1074,    50] loss: 19.90754
[1074,   100] loss: 23.12071
[1074,   150] loss: 18.60423
val error: 222.48761
[1075,    50] loss: 19.98434
[1075,   100] loss: 22.35209
[1075,   150] loss: 24.37106
val error: 242.58658
[1076,    50] loss: 32.23184
[1076,   100] loss: 20.86222
[1076,   150] loss: 24.44897
val error: 239.60144
[1077,    50] loss: 63.42568
[1077,   100] loss: 67.41210
[1077,   150] loss: 55.50572
val error: 338.36749
[1078,    50] loss: 104.67229
[1078,   100] loss: 61.37384
[1078,   150] loss: 46.10901
val error: 208.31351
[1079,    50] loss: 39.97736
[1079,   100] loss: 60.52884
[1079,   150] loss: 37.08155
val error: 288.88785
[1080,    50] loss: 51.02185
[1080,   100] loss: 32.68452
[1080,   150] loss: 52.43377
val error: 340.66742
[1081,    50] loss: 62.68059
[1081,   100] loss: 40.80878
[1081,   150] loss: 28.54173
val error: 222.56479
[1082,    50] loss: 46.92774
[1082,   100] loss: 25.28607
[1082,   150] loss: 24.52958
val error: 237.96942
[1083,    50] loss: 23.40047
[1083,   100] loss: 23.10924
[1083,   150] loss: 24.34951
val error: 209.33932
[1084,    50] loss: 19.59327
[1084,   100] loss: 21.78258
[1084,   150] loss: 11.06263
val error: 232.54779
[1085,    50] loss: 14.04839
[1085,   100] loss: 14.08125
[1085,   150] loss: 25.07696
val error: 225.94855
[1086,    50] loss: 19.83016
[1086,   100] loss: 15.92587
[1086,   150] loss: 22.55482
val error: 196.90117
[1087,    50] loss: 19.37606
[1087,   100] loss: 16.37093
[1087,   150] loss: 23.13507
val error: 198.15053
[1088,    50] loss: 26.86471
[1088,   100] loss: 41.06366
[1088,   150] loss: 26.78361
val error: 208.99020
[1089,    50] loss: 30.73271
[1089,   100] loss: 18.84592
[1089,   150] loss: 24.56784
val error: 229.50621
[1090,    50] loss: 31.35555
[1090,   100] loss: 26.13451
[1090,   150] loss: 17.84502
val error: 251.17709
[1091,    50] loss: 32.11277
[1091,   100] loss: 20.58825
[1091,   150] loss: 35.46890
val error: 221.71085
[1092,    50] loss: 27.27541
[1092,   100] loss: 18.09386
[1092,   150] loss: 17.38200
val error: 209.99266
[1093,    50] loss: 19.65243
[1093,   100] loss: 35.73330
[1093,   150] loss: 18.08838
val error: 218.61462
[1094,    50] loss: 17.21374
[1094,   100] loss: 12.96490
[1094,   150] loss: 18.48636
val error: 190.02148
[1095,    50] loss: 10.54410
[1095,   100] loss: 12.90788
[1095,   150] loss: 13.12549
val error: 169.49557
[1096,    50] loss: 11.46995
[1096,   100] loss: 13.01814
[1096,   150] loss: 13.51262
val error: 211.29326
[1097,    50] loss: 13.66586
[1097,   100] loss: 17.51372
[1097,   150] loss: 13.77694
val error: 208.48117
[1098,    50] loss: 11.44919
[1098,   100] loss: 19.67812
[1098,   150] loss: 18.21663
val error: 178.00421
[1099,    50] loss: 15.08635
[1099,   100] loss: 41.64470
[1099,   150] loss: 41.32489
val error: 221.71054
[1100,    50] loss: 43.21263
[1100,   100] loss: 41.21811
[1100,   150] loss: 19.80754
val error: 189.83466
Finished Training
